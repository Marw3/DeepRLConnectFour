{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e85fff",
   "metadata": {},
   "source": [
    "## Training and evaluation of decision transformer\n",
    "\n",
    "---\n",
    "\n",
    "> Internship neural networks\n",
    ">\n",
    "> Group 4: Reinforcement learning\n",
    ">\n",
    "> Deadline 28.02.23 23:59\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da10a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d9ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../Environment/Connect4.ipynb\"\n",
    "%run \"../utils/utils.ipynb\"\n",
    "%run \"../OtherAgents/Agents.ipynb\"\n",
    "%run \"utils.ipynb\"\n",
    "%run \"DecisionTransformer.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80fddc",
   "metadata": {},
   "source": [
    "# Training parameters and evaluation device\n",
    "\n",
    "The used hyperparameters in this notebook are examples for the code submission. In our paper we present the results for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee75ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device set to:  cuda\n"
     ]
    }
   ],
   "source": [
    "rtg_target = 10            # target return to go (decision transformer looks for trajectories with this rtg)\n",
    "env_name = 'Connect4'      # name of environment  \n",
    "vocab_size = 7             # number of actions\n",
    "state_dim = 42             # dimension of the observations\n",
    "act_dim = 1                # dimension of the actions\n",
    "max_timestep=21            # maximum length of a game\n",
    "\n",
    "num_eval_ep = 100           # num of evaluation episodes per iteration\n",
    "\n",
    "batch_size = 64            # training batch size\n",
    "lr = 1e-4                   # learning rate\n",
    "wt_decay = 1e-4             # weight decay\n",
    "warmup_steps = 10000        # warmup steps for lr scheduler\n",
    "\n",
    "# total updates of dt = max_train_iters x num_updates_per_iter\n",
    "num_updates_per_iter = 1000\n",
    "\n",
    "context_len = 10        # K in decision transformer\n",
    "n_blocks = 4            # num of transformer blocks\n",
    "hidden_dim = 128         # hidden dim of transformer\n",
    "n_heads = 2             # num of transformer heads\n",
    "dropout_p = 0.1         # dropout probability\n",
    "\n",
    "# saves model and csv in this directory\n",
    "log_dir = \"./dt_training/\"\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# evaluation device\n",
    "device_name = 'cuda'\n",
    "device = torch.device(device_name)\n",
    "print(\"device set to: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ee133",
   "metadata": {},
   "source": [
    "# Create evaluation file + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06922d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "start time: 23-02-28-17-54-34\n",
      "============================================================\n",
      "device set to: cuda\n",
      "model save path: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34.pt\n",
      "log csv save path: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_log_23-02-28-17-54-34.csv\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now().replace(microsecond=0)\n",
    "\n",
    "start_time_str = start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "prefix = \"dt_\" + env_name + \"_batch_size=\" + str(batch_size) + \"_context_len=\" + str(context_len) + \"_n_blocks=\" + str(n_blocks) + \"_hidden_dim=\" + str(hidden_dim) + \"_n_heads=\" + str(n_heads)\n",
    "\n",
    "save_model_name =  prefix + \"_model_\" + start_time_str + \".pt\"\n",
    "save_model_path = os.path.join(log_dir, save_model_name)\n",
    "save_best_model_path = save_model_path[:-3] + \"_best.pt\"\n",
    "save_best_model_path_NM = save_model_path[:-3] + \"_best_againstNM.pt\"\n",
    "\n",
    "log_name = prefix + \"_log_\" + start_time_str + \".csv\"\n",
    "log_path = os.path.join(log_dir, log_name)\n",
    "\n",
    "\n",
    "csv_writer = csv.writer(open(log_path, 'a', 1))\n",
    "csv_header = ([\"duration\", \"num_updates\", \"action_loss\", \n",
    "               \"eval_avg_reward\", \"eval_avg_ep_len\", \"eval_win_rate\",\n",
    "               \"eval_avg_rewardP2\", \"eval_avg_ep_lenP2\", \"eval_win_rateP2\",\n",
    "               \"eval_avg_rewardNM\", \"eval_avg_ep_lenNM\", \"eval_win_rateNM\",\n",
    "               \"eval_avg_rewardP2NM\", \"eval_avg_ep_lenP2NM\", \"eval_win_rateP2NM\"])\n",
    "\n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"start time: \" + start_time_str)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"device set to: \" + str(device))\n",
    "print(\"model save path: \" + save_model_path)\n",
    "print(\"log csv save path: \" + log_path)\n",
    "\n",
    "max_avg_reward = -1.0\n",
    "max_avg_reward_NM = -1.0\n",
    "total_updates = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7a791",
   "metadata": {},
   "source": [
    "# Define agent and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70e91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "agent = DTAgent(state_dim=state_dim,\n",
    "            act_dim=act_dim,\n",
    "            n_blocks=n_blocks,\n",
    "            hidden_dim=hidden_dim,\n",
    "            context_len=context_len,\n",
    "            n_heads=n_heads,\n",
    "            drop_p=dropout_p,\n",
    "            rtg_target = rtg_target,\n",
    "            vocab_size = vocab_size)\n",
    "\n",
    "optimizer = torch.optim.AdamW(agent.model.parameters(), lr=lr, weight_decay=wt_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda steps: min((steps+1)/warmup_steps, 1))\n",
    "\n",
    "env = Connect4()\n",
    "\n",
    "randomPlayer = RandomAgent()\n",
    "negaMax = NegaMaxAgent(env, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb492af",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ffb4fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                        | 1/20 [01:54<36:14, 114.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:02:03\n",
      "num of updates: 1000\n",
      "action loss: 1.98899\n",
      "eval avg reward: 4.20000\n",
      "eval avg ep len: 8.32000\n",
      "eval_win_rate: 0.71\n",
      "eval avg reward as player2: 4.60000\n",
      "eval avg ep len as player2: 8.97000\n",
      "eval_win_rate as player2: 0.73\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 10.52000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -8.20000\n",
      "eval avg ep len as player2 against NM: 8.87000\n",
      "eval_win_rate as player2 against NM: 0.09\n",
      "max avg reward: -1.00000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▏                                     | 2/20 [03:34<31:43, 105.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:03:42\n",
      "num of updates: 2000\n",
      "action loss: 1.95200\n",
      "eval avg reward: 8.00000\n",
      "eval avg ep len: 7.38000\n",
      "eval_win_rate: 0.90\n",
      "eval avg reward as player2: 7.40000\n",
      "eval avg ep len as player2: 6.23000\n",
      "eval_win_rate as player2: 0.87\n",
      "eval avg reward against NM: -4.80000\n",
      "eval avg ep len against NM: 9.97000\n",
      "eval_win_rate against NM: 0.26\n",
      "eval avg reward as player2 against NM: -9.40000\n",
      "eval avg ep len as player2 against NM: 6.83000\n",
      "eval_win_rate as player2 against NM: 0.03\n",
      "max avg reward: 4.20000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▎                                   | 3/20 [05:21<30:11, 106.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:05:30\n",
      "num of updates: 3000\n",
      "action loss: 1.94827\n",
      "eval avg reward: 6.20000\n",
      "eval avg ep len: 9.69000\n",
      "eval_win_rate: 0.81\n",
      "eval avg reward as player2: 6.60000\n",
      "eval avg ep len as player2: 7.58000\n",
      "eval_win_rate as player2: 0.83\n",
      "eval avg reward against NM: -6.20000\n",
      "eval avg ep len against NM: 9.34000\n",
      "eval_win_rate against NM: 0.19\n",
      "eval avg reward as player2 against NM: -9.60000\n",
      "eval avg ep len as player2 against NM: 6.48000\n",
      "eval_win_rate as player2 against NM: 0.02\n",
      "max avg reward: 8.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▍                                 | 4/20 [06:59<27:31, 103.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:07:08\n",
      "num of updates: 4000\n",
      "action loss: 1.94685\n",
      "eval avg reward: 7.60000\n",
      "eval avg ep len: 6.30000\n",
      "eval_win_rate: 0.88\n",
      "eval avg reward as player2: 7.20000\n",
      "eval avg ep len as player2: 6.33000\n",
      "eval_win_rate as player2: 0.86\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 10.68000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 6.36000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████▌                               | 5/20 [08:44<25:54, 103.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:08:52\n",
      "num of updates: 5000\n",
      "action loss: 1.94612\n",
      "eval avg reward: 7.60000\n",
      "eval avg ep len: 7.13000\n",
      "eval_win_rate: 0.88\n",
      "eval avg reward as player2: 6.80000\n",
      "eval avg ep len as player2: 6.05000\n",
      "eval_win_rate as player2: 0.84\n",
      "eval avg reward against NM: -9.40000\n",
      "eval avg ep len against NM: 10.01000\n",
      "eval_win_rate against NM: 0.03\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.29000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▌                             | 6/20 [10:31<24:26, 104.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:10:39\n",
      "num of updates: 6000\n",
      "action loss: 1.94528\n",
      "eval avg reward: 7.20000\n",
      "eval avg ep len: 8.46000\n",
      "eval_win_rate: 0.86\n",
      "eval avg reward as player2: 5.20000\n",
      "eval avg ep len as player2: 8.20000\n",
      "eval_win_rate as player2: 0.76\n",
      "eval avg reward against NM: -5.60000\n",
      "eval avg ep len against NM: 9.57000\n",
      "eval_win_rate against NM: 0.22\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.95000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|██████████████▋                           | 7/20 [12:21<23:04, 106.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:12:29\n",
      "num of updates: 7000\n",
      "action loss: 1.94484\n",
      "eval avg reward: 6.40000\n",
      "eval avg ep len: 8.71000\n",
      "eval_win_rate: 0.82\n",
      "eval avg reward as player2: 5.20000\n",
      "eval avg ep len as player2: 7.88000\n",
      "eval_win_rate as player2: 0.76\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 9.07000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.57000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████▊                         | 8/20 [14:02<20:58, 104.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:14:11\n",
      "num of updates: 8000\n",
      "action loss: 1.94445\n",
      "eval avg reward: 7.00000\n",
      "eval avg ep len: 7.13000\n",
      "eval_win_rate: 0.85\n",
      "eval avg reward as player2: 7.40000\n",
      "eval avg ep len as player2: 5.90000\n",
      "eval_win_rate as player2: 0.87\n",
      "eval avg reward against NM: -4.00000\n",
      "eval avg ep len against NM: 11.29000\n",
      "eval_win_rate against NM: 0.30\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.04000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████▉                       | 9/20 [15:44<19:04, 104.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:15:53\n",
      "num of updates: 9000\n",
      "action loss: 1.94409\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 6.92000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 5.60000\n",
      "eval avg ep len as player2: 7.69000\n",
      "eval_win_rate as player2: 0.78\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 8.00000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -9.20000\n",
      "eval avg ep len as player2 against NM: 6.70000\n",
      "eval_win_rate as player2 against NM: 0.04\n",
      "max avg reward: 8.00000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████▌                    | 10/20 [17:34<17:38, 105.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:17:43\n",
      "num of updates: 10000\n",
      "action loss: 1.94337\n",
      "eval avg reward: 4.60000\n",
      "eval avg ep len: 9.05000\n",
      "eval_win_rate: 0.73\n",
      "eval avg reward as player2: 5.60000\n",
      "eval avg ep len as player2: 8.32000\n",
      "eval_win_rate as player2: 0.78\n",
      "eval avg reward against NM: -6.40000\n",
      "eval avg ep len against NM: 10.66000\n",
      "eval_win_rate against NM: 0.18\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.55000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████▌                  | 11/20 [19:34<16:30, 110.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:19:42\n",
      "num of updates: 11000\n",
      "action loss: 1.94299\n",
      "eval avg reward: 2.00000\n",
      "eval avg ep len: 10.31000\n",
      "eval_win_rate: 0.60\n",
      "eval avg reward as player2: 0.40000\n",
      "eval avg ep len as player2: 10.20000\n",
      "eval_win_rate as player2: 0.52\n",
      "eval avg reward against NM: -5.20000\n",
      "eval avg ep len against NM: 13.36000\n",
      "eval_win_rate against NM: 0.24\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.50000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████▌                | 12/20 [21:32<15:00, 112.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:21:41\n",
      "num of updates: 12000\n",
      "action loss: 1.94262\n",
      "eval avg reward: 3.40000\n",
      "eval avg ep len: 10.67000\n",
      "eval_win_rate: 0.67\n",
      "eval avg reward as player2: 1.40000\n",
      "eval avg ep len as player2: 10.46000\n",
      "eval_win_rate as player2: 0.57\n",
      "eval avg reward against NM: -2.40000\n",
      "eval avg ep len against NM: 11.13000\n",
      "eval_win_rate against NM: 0.38\n",
      "eval avg reward as player2 against NM: -9.40000\n",
      "eval avg ep len as player2 against NM: 8.07000\n",
      "eval_win_rate as player2 against NM: 0.03\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████▋              | 13/20 [23:17<12:52, 110.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:23:26\n",
      "num of updates: 13000\n",
      "action loss: 1.94208\n",
      "eval avg reward: 4.80000\n",
      "eval avg ep len: 9.92000\n",
      "eval_win_rate: 0.74\n",
      "eval avg reward as player2: 2.00000\n",
      "eval avg ep len as player2: 9.94000\n",
      "eval_win_rate as player2: 0.60\n",
      "eval avg reward against NM: -5.60000\n",
      "eval avg ep len against NM: 8.54000\n",
      "eval_win_rate against NM: 0.22\n",
      "eval avg reward as player2 against NM: -9.60000\n",
      "eval avg ep len as player2 against NM: 7.62000\n",
      "eval_win_rate as player2 against NM: 0.02\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████▋            | 14/20 [24:56<10:41, 106.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:25:05\n",
      "num of updates: 14000\n",
      "action loss: 1.94181\n",
      "eval avg reward: 5.00000\n",
      "eval avg ep len: 8.27000\n",
      "eval_win_rate: 0.75\n",
      "eval avg reward as player2: 5.40000\n",
      "eval avg ep len as player2: 7.56000\n",
      "eval_win_rate as player2: 0.77\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 8.50000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 6.30000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████▊          | 15/20 [26:39<08:47, 105.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:26:47\n",
      "num of updates: 15000\n",
      "action loss: 1.94109\n",
      "eval avg reward: 5.20000\n",
      "eval avg ep len: 7.93000\n",
      "eval_win_rate: 0.76\n",
      "eval avg reward as player2: 3.80000\n",
      "eval avg ep len as player2: 8.25000\n",
      "eval_win_rate as player2: 0.69\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 7.54000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 6.84000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████▊        | 16/20 [28:17<06:53, 103.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:28:25\n",
      "num of updates: 16000\n",
      "action loss: 1.94046\n",
      "eval avg reward: 2.60000\n",
      "eval avg ep len: 9.77000\n",
      "eval_win_rate: 0.63\n",
      "eval avg reward as player2: 5.20000\n",
      "eval avg ep len as player2: 8.41000\n",
      "eval_win_rate as player2: 0.76\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 6.00000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 6.48000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|██████████████████████████████████▊      | 17/20 [29:56<05:06, 102.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:30:05\n",
      "num of updates: 17000\n",
      "action loss: 1.94045\n",
      "eval avg reward: 6.20000\n",
      "eval avg ep len: 8.61000\n",
      "eval_win_rate: 0.81\n",
      "eval avg reward as player2: 5.60000\n",
      "eval avg ep len as player2: 7.12000\n",
      "eval_win_rate as player2: 0.78\n",
      "eval avg reward against NM: -8.80000\n",
      "eval avg ep len against NM: 9.47000\n",
      "eval_win_rate against NM: 0.06\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 6.26000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████▉    | 18/20 [31:41<03:26, 103.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:31:50\n",
      "num of updates: 18000\n",
      "action loss: 1.93986\n",
      "eval avg reward: 6.80000\n",
      "eval avg ep len: 8.17000\n",
      "eval_win_rate: 0.84\n",
      "eval avg reward as player2: 5.00000\n",
      "eval avg ep len as player2: 8.13000\n",
      "eval_win_rate as player2: 0.75\n",
      "eval avg reward against NM: -9.80000\n",
      "eval avg ep len against NM: 8.35000\n",
      "eval_win_rate against NM: 0.01\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 6.81000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████▉  | 19/20 [33:16<01:40, 100.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:33:24\n",
      "num of updates: 19000\n",
      "action loss: 1.93921\n",
      "eval avg reward: 7.60000\n",
      "eval avg ep len: 8.60000\n",
      "eval_win_rate: 0.88\n",
      "eval avg reward as player2: 5.80000\n",
      "eval avg ep len as player2: 7.42000\n",
      "eval_win_rate as player2: 0.79\n",
      "eval avg reward against NM: -9.80000\n",
      "eval avg ep len against NM: 7.50000\n",
      "eval_win_rate against NM: 0.01\n",
      "eval avg reward as player2 against NM: -9.70000\n",
      "eval avg ep len as player2 against NM: 6.91000\n",
      "eval_win_rate as player2 against NM: 0.03\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 20/20 [35:00<00:00, 105.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:35:09\n",
      "num of updates: 20000\n",
      "action loss: 1.93874\n",
      "eval avg reward: 7.60000\n",
      "eval avg ep len: 6.74000\n",
      "eval_win_rate: 0.88\n",
      "eval avg reward as player2: 6.40000\n",
      "eval avg ep len as player2: 6.56000\n",
      "eval_win_rate as player2: 0.82\n",
      "eval avg reward against NM: -10.00000\n",
      "eval avg ep len against NM: 8.00000\n",
      "eval_win_rate against NM: 0.00\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 7.41000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n",
      "saving current model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_20000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|█▍                                        | 1/30 [01:52<54:23, 112.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:37:02\n",
      "num of updates: 21000\n",
      "action loss: 1.72372\n",
      "eval avg reward: 6.60000\n",
      "eval avg ep len: 8.44000\n",
      "eval_win_rate: 0.83\n",
      "eval avg reward as player2: 6.60000\n",
      "eval avg ep len as player2: 7.53000\n",
      "eval_win_rate as player2: 0.83\n",
      "eval avg reward against NM: -7.80000\n",
      "eval avg ep len against NM: 9.73000\n",
      "eval_win_rate against NM: 0.11\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 7.50000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                       | 2/30 [03:44<52:28, 112.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:38:54\n",
      "num of updates: 22000\n",
      "action loss: 1.51932\n",
      "eval avg reward: 7.20000\n",
      "eval avg ep len: 7.66000\n",
      "eval_win_rate: 0.86\n",
      "eval avg reward as player2: 6.60000\n",
      "eval avg ep len as player2: 7.96000\n",
      "eval_win_rate as player2: 0.83\n",
      "eval avg reward against NM: -6.60000\n",
      "eval avg ep len against NM: 9.56000\n",
      "eval_win_rate against NM: 0.17\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 9.68000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▏                                     | 3/30 [05:47<52:45, 117.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:40:57\n",
      "num of updates: 23000\n",
      "action loss: 1.38264\n",
      "eval avg reward: 7.60000\n",
      "eval avg ep len: 7.81000\n",
      "eval_win_rate: 0.88\n",
      "eval avg reward as player2: 8.40000\n",
      "eval avg ep len as player2: 7.41000\n",
      "eval_win_rate as player2: 0.92\n",
      "eval avg reward against NM: -9.40000\n",
      "eval avg ep len against NM: 9.86000\n",
      "eval_win_rate against NM: 0.03\n",
      "eval avg reward as player2 against NM: -9.00000\n",
      "eval avg ep len as player2 against NM: 11.46000\n",
      "eval_win_rate as player2 against NM: 0.05\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▌                                    | 4/30 [07:51<51:49, 119.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:43:00\n",
      "num of updates: 24000\n",
      "action loss: 1.28816\n",
      "eval avg reward: 8.00000\n",
      "eval avg ep len: 8.16000\n",
      "eval_win_rate: 0.90\n",
      "eval avg reward as player2: 8.40000\n",
      "eval avg ep len as player2: 7.50000\n",
      "eval_win_rate as player2: 0.92\n",
      "eval avg reward against NM: -7.20000\n",
      "eval avg ep len against NM: 10.04000\n",
      "eval_win_rate against NM: 0.14\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 9.86000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████                                   | 5/30 [09:55<50:31, 121.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:45:05\n",
      "num of updates: 25000\n",
      "action loss: 1.21891\n",
      "eval avg reward: 8.40000\n",
      "eval avg ep len: 8.00000\n",
      "eval_win_rate: 0.92\n",
      "eval avg reward as player2: 8.60000\n",
      "eval avg ep len as player2: 7.24000\n",
      "eval_win_rate as player2: 0.93\n",
      "eval avg reward against NM: -8.60000\n",
      "eval avg ep len against NM: 11.59000\n",
      "eval_win_rate against NM: 0.07\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 9.71000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▍                                 | 6/30 [12:00<49:03, 122.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:47:10\n",
      "num of updates: 26000\n",
      "action loss: 1.16735\n",
      "eval avg reward: 8.40000\n",
      "eval avg ep len: 7.19000\n",
      "eval_win_rate: 0.92\n",
      "eval avg reward as player2: 9.00000\n",
      "eval avg ep len as player2: 6.88000\n",
      "eval_win_rate as player2: 0.95\n",
      "eval avg reward against NM: -9.20000\n",
      "eval avg ep len against NM: 11.81000\n",
      "eval_win_rate against NM: 0.04\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 10.23000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▊                                | 7/30 [14:05<47:17, 123.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:49:15\n",
      "num of updates: 27000\n",
      "action loss: 1.12619\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 8.06000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 8.60000\n",
      "eval avg ep len as player2: 7.01000\n",
      "eval_win_rate as player2: 0.93\n",
      "eval avg reward against NM: -7.00000\n",
      "eval avg ep len against NM: 9.93000\n",
      "eval_win_rate against NM: 0.15\n",
      "eval avg reward as player2 against NM: -10.00000\n",
      "eval avg ep len as player2 against NM: 10.82000\n",
      "eval_win_rate as player2 against NM: 0.00\n",
      "max avg reward: 8.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████▏                              | 8/30 [16:09<45:20, 123.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:51:19\n",
      "num of updates: 28000\n",
      "action loss: 1.09437\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.57000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 6.68000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: 0.60000\n",
      "eval avg ep len against NM: 9.73000\n",
      "eval_win_rate against NM: 0.53\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 10.58000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 8.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best_againstNM.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▌                             | 9/30 [18:11<43:01, 122.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:53:20\n",
      "num of updates: 29000\n",
      "action loss: 1.06794\n",
      "eval avg reward: 8.60000\n",
      "eval avg ep len: 7.94000\n",
      "eval_win_rate: 0.93\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 7.11000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: 2.60000\n",
      "eval avg ep len against NM: 9.50000\n",
      "eval_win_rate against NM: 0.63\n",
      "eval avg reward as player2 against NM: -9.40000\n",
      "eval avg ep len as player2 against NM: 10.13000\n",
      "eval_win_rate as player2 against NM: 0.04\n",
      "max avg reward: 9.40000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best_againstNM.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████▋                           | 10/30 [20:27<42:21, 127.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:55:37\n",
      "num of updates: 30000\n",
      "action loss: 1.04736\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 7.24000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 8.80000\n",
      "eval avg ep len as player2: 7.37000\n",
      "eval_win_rate as player2: 0.94\n",
      "eval avg reward against NM: -7.00000\n",
      "eval avg ep len against NM: 12.16000\n",
      "eval_win_rate against NM: 0.15\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 10.40000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 9.40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████                          | 11/30 [22:36<40:28, 127.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:57:46\n",
      "num of updates: 31000\n",
      "action loss: 1.02589\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.81000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.60000\n",
      "eval avg ep len as player2: 6.88000\n",
      "eval_win_rate as player2: 0.98\n",
      "eval avg reward against NM: -6.80000\n",
      "eval avg ep len against NM: 10.42000\n",
      "eval_win_rate against NM: 0.16\n",
      "eval avg reward as player2 against NM: -9.00000\n",
      "eval avg ep len as player2 against NM: 12.55000\n",
      "eval_win_rate as player2 against NM: 0.05\n",
      "max avg reward: 9.40000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████▍                        | 12/30 [24:51<38:55, 129.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:00:01\n",
      "num of updates: 32000\n",
      "action loss: 1.01185\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 8.08000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 6.89000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: -6.80000\n",
      "eval avg ep len against NM: 13.36000\n",
      "eval_win_rate against NM: 0.16\n",
      "eval avg reward as player2 against NM: -9.60000\n",
      "eval avg ep len as player2 against NM: 10.65000\n",
      "eval_win_rate as player2 against NM: 0.02\n",
      "max avg reward: 9.40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|█████████████████▊                       | 13/30 [27:05<37:10, 131.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:02:15\n",
      "num of updates: 33000\n",
      "action loss: 0.99330\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.41000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.00000\n",
      "eval avg ep len as player2: 6.94000\n",
      "eval_win_rate as player2: 0.95\n",
      "eval avg reward against NM: -7.20000\n",
      "eval avg ep len against NM: 11.06000\n",
      "eval_win_rate against NM: 0.14\n",
      "eval avg reward as player2 against NM: -9.80000\n",
      "eval avg ep len as player2 against NM: 11.00000\n",
      "eval_win_rate as player2 against NM: 0.01\n",
      "max avg reward: 9.40000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████▏                     | 14/30 [29:15<34:53, 130.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:04:25\n",
      "num of updates: 34000\n",
      "action loss: 0.97882\n",
      "eval avg reward: 9.60000\n",
      "eval avg ep len: 7.34000\n",
      "eval_win_rate: 0.98\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 7.16000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: -1.20000\n",
      "eval avg ep len against NM: 10.01000\n",
      "eval_win_rate against NM: 0.44\n",
      "eval avg reward as player2 against NM: -9.30000\n",
      "eval avg ep len as player2 against NM: 11.11000\n",
      "eval_win_rate as player2 against NM: 0.04\n",
      "max avg reward: 9.40000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████▌                    | 15/30 [31:41<33:51, 135.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:06:51\n",
      "num of updates: 35000\n",
      "action loss: 0.96749\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 7.73000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 9.80000\n",
      "eval avg ep len as player2: 6.67000\n",
      "eval_win_rate as player2: 0.99\n",
      "eval avg reward against NM: -7.00000\n",
      "eval avg ep len against NM: 10.31000\n",
      "eval_win_rate against NM: 0.15\n",
      "eval avg reward as player2 against NM: -9.00000\n",
      "eval avg ep len as player2 against NM: 12.81000\n",
      "eval_win_rate as player2 against NM: 0.07\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████▊                   | 16/30 [34:01<31:52, 136.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:09:11\n",
      "num of updates: 36000\n",
      "action loss: 0.95747\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 8.02000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 7.41000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: -5.60000\n",
      "eval avg ep len against NM: 10.30000\n",
      "eval_win_rate against NM: 0.22\n",
      "eval avg reward as player2 against NM: -9.10000\n",
      "eval avg ep len as player2 against NM: 10.64000\n",
      "eval_win_rate as player2 against NM: 0.05\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████▏                 | 17/30 [36:17<29:33, 136.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:11:26\n",
      "num of updates: 37000\n",
      "action loss: 0.94237\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.45000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 8.60000\n",
      "eval avg ep len as player2: 6.92000\n",
      "eval_win_rate as player2: 0.93\n",
      "eval avg reward against NM: -4.40000\n",
      "eval avg ep len against NM: 11.60000\n",
      "eval_win_rate against NM: 0.28\n",
      "eval avg reward as player2 against NM: -9.00000\n",
      "eval avg ep len as player2 against NM: 11.01000\n",
      "eval_win_rate as player2 against NM: 0.05\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████▌                | 18/30 [38:40<27:42, 138.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:13:50\n",
      "num of updates: 38000\n",
      "action loss: 0.93581\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 8.37000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.40000\n",
      "eval avg ep len as player2: 6.86000\n",
      "eval_win_rate as player2: 0.97\n",
      "eval avg reward against NM: -4.60000\n",
      "eval avg ep len against NM: 12.11000\n",
      "eval_win_rate against NM: 0.27\n",
      "eval avg reward as player2 against NM: -8.20000\n",
      "eval avg ep len as player2 against NM: 11.10000\n",
      "eval_win_rate as player2 against NM: 0.10\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|█████████████████████████▉               | 19/30 [41:01<25:31, 139.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:16:11\n",
      "num of updates: 39000\n",
      "action loss: 0.92617\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 7.86000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 7.33000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: -5.00000\n",
      "eval avg ep len against NM: 10.89000\n",
      "eval_win_rate against NM: 0.25\n",
      "eval avg reward as player2 against NM: -9.10000\n",
      "eval avg ep len as player2 against NM: 11.08000\n",
      "eval_win_rate as player2 against NM: 0.05\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████▎             | 20/30 [43:23<23:20, 140.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:18:33\n",
      "num of updates: 40000\n",
      "action loss: 0.91727\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 7.84000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 8.60000\n",
      "eval avg ep len as player2: 6.94000\n",
      "eval_win_rate as player2: 0.93\n",
      "eval avg reward against NM: -5.80000\n",
      "eval avg ep len against NM: 10.41000\n",
      "eval_win_rate against NM: 0.21\n",
      "eval avg reward as player2 against NM: -9.60000\n",
      "eval avg ep len as player2 against NM: 10.98000\n",
      "eval_win_rate as player2 against NM: 0.02\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████▋            | 21/30 [45:43<21:00, 140.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:20:53\n",
      "num of updates: 41000\n",
      "action loss: 0.90819\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.80000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 10.00000\n",
      "eval avg ep len as player2: 7.09000\n",
      "eval_win_rate as player2: 1.00\n",
      "eval avg reward against NM: -6.40000\n",
      "eval avg ep len against NM: 11.64000\n",
      "eval_win_rate against NM: 0.18\n",
      "eval avg reward as player2 against NM: -9.60000\n",
      "eval avg ep len as player2 against NM: 10.89000\n",
      "eval_win_rate as player2 against NM: 0.03\n",
      "max avg reward: 9.60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████           | 22/30 [48:02<18:38, 139.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:23:12\n",
      "num of updates: 42000\n",
      "action loss: 0.90015\n",
      "eval avg reward: 9.80000\n",
      "eval avg ep len: 7.99000\n",
      "eval_win_rate: 0.99\n",
      "eval avg reward as player2: 8.60000\n",
      "eval avg ep len as player2: 7.38000\n",
      "eval_win_rate as player2: 0.93\n",
      "eval avg reward against NM: -5.00000\n",
      "eval avg ep len against NM: 11.27000\n",
      "eval_win_rate against NM: 0.25\n",
      "eval avg reward as player2 against NM: -8.20000\n",
      "eval avg ep len as player2 against NM: 11.97000\n",
      "eval_win_rate as player2 against NM: 0.09\n",
      "max avg reward: 9.60000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████▍         | 23/30 [50:18<16:10, 138.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:25:28\n",
      "num of updates: 43000\n",
      "action loss: 0.89316\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.36000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 7.22000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: -5.40000\n",
      "eval avg ep len against NM: 10.24000\n",
      "eval_win_rate against NM: 0.23\n",
      "eval avg reward as player2 against NM: -8.60000\n",
      "eval avg ep len as player2 against NM: 10.86000\n",
      "eval_win_rate as player2 against NM: 0.07\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████▊        | 24/30 [52:40<13:57, 139.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:27:50\n",
      "num of updates: 44000\n",
      "action loss: 0.88630\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.93000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 8.80000\n",
      "eval avg ep len as player2: 6.89000\n",
      "eval_win_rate as player2: 0.94\n",
      "eval avg reward against NM: -3.40000\n",
      "eval avg ep len against NM: 11.45000\n",
      "eval_win_rate against NM: 0.33\n",
      "eval avg reward as player2 against NM: -8.40000\n",
      "eval avg ep len as player2 against NM: 11.91000\n",
      "eval_win_rate as player2 against NM: 0.08\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████▏      | 25/30 [55:03<11:43, 140.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:30:13\n",
      "num of updates: 45000\n",
      "action loss: 0.87915\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 8.13000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.80000\n",
      "eval avg ep len as player2: 6.66000\n",
      "eval_win_rate as player2: 0.99\n",
      "eval avg reward against NM: -7.20000\n",
      "eval avg ep len against NM: 12.27000\n",
      "eval_win_rate against NM: 0.14\n",
      "eval avg reward as player2 against NM: -8.50000\n",
      "eval avg ep len as player2 against NM: 12.22000\n",
      "eval_win_rate as player2 against NM: 0.08\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████▌     | 26/30 [57:20<09:17, 139.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:32:30\n",
      "num of updates: 46000\n",
      "action loss: 0.87167\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.57000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.60000\n",
      "eval avg ep len as player2: 7.56000\n",
      "eval_win_rate as player2: 0.98\n",
      "eval avg reward against NM: -2.60000\n",
      "eval avg ep len against NM: 12.45000\n",
      "eval_win_rate against NM: 0.37\n",
      "eval avg reward as player2 against NM: -8.20000\n",
      "eval avg ep len as player2 against NM: 10.31000\n",
      "eval_win_rate as player2 against NM: 0.09\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████▉    | 27/30 [59:37<06:56, 138.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:34:47\n",
      "num of updates: 47000\n",
      "action loss: 0.86688\n",
      "eval avg reward: 9.60000\n",
      "eval avg ep len: 8.46000\n",
      "eval_win_rate: 0.98\n",
      "eval avg reward as player2: 9.40000\n",
      "eval avg ep len as player2: 7.55000\n",
      "eval_win_rate as player2: 0.97\n",
      "eval avg reward against NM: -5.00000\n",
      "eval avg ep len against NM: 11.63000\n",
      "eval_win_rate against NM: 0.25\n",
      "eval avg reward as player2 against NM: -4.70000\n",
      "eval avg ep len as player2 against NM: 11.25000\n",
      "eval_win_rate as player2 against NM: 0.29\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████▍  | 28/30 [1:01:58<04:38, 139.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:37:07\n",
      "num of updates: 48000\n",
      "action loss: 0.86063\n",
      "eval avg reward: 9.80000\n",
      "eval avg ep len: 7.17000\n",
      "eval_win_rate: 0.99\n",
      "eval avg reward as player2: 9.80000\n",
      "eval avg ep len as player2: 7.03000\n",
      "eval_win_rate as player2: 0.99\n",
      "eval avg reward against NM: 0.00000\n",
      "eval avg ep len against NM: 12.82000\n",
      "eval_win_rate against NM: 0.50\n",
      "eval avg reward as player2 against NM: -9.00000\n",
      "eval avg ep len as player2 against NM: 11.78000\n",
      "eval_win_rate as player2 against NM: 0.05\n",
      "max avg reward: 9.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████▋ | 29/30 [1:04:23<02:21, 141.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:39:33\n",
      "num of updates: 49000\n",
      "action loss: 0.85507\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.80000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 9.60000\n",
      "eval avg ep len as player2: 7.09000\n",
      "eval_win_rate as player2: 0.98\n",
      "eval avg reward against NM: -0.60000\n",
      "eval avg ep len against NM: 11.08000\n",
      "eval_win_rate against NM: 0.47\n",
      "eval avg reward as player2 against NM: -7.20000\n",
      "eval avg ep len as player2 against NM: 12.32000\n",
      "eval_win_rate as player2 against NM: 0.17\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 30/30 [1:06:46<00:00, 133.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:41:56\n",
      "num of updates: 50000\n",
      "action loss: 0.84728\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 8.09000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 9.80000\n",
      "eval avg ep len as player2: 6.99000\n",
      "eval_win_rate as player2: 0.99\n",
      "eval avg reward against NM: -3.00000\n",
      "eval avg ep len against NM: 11.66000\n",
      "eval_win_rate against NM: 0.35\n",
      "eval avg reward as player2 against NM: -7.20000\n",
      "eval avg ep len as player2 against NM: 12.52000\n",
      "eval_win_rate as player2 against NM: 0.17\n",
      "max avg reward: 9.80000\n",
      "saving current model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_50000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|█▎                                      | 1/30 [02:26<1:10:40, 146.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:44:23\n",
      "num of updates: 51000\n",
      "action loss: 1.33397\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 7.78000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 8.60000\n",
      "eval avg ep len as player2: 7.42000\n",
      "eval_win_rate as player2: 0.93\n",
      "eval avg reward against NM: -2.20000\n",
      "eval avg ep len against NM: 13.11000\n",
      "eval_win_rate against NM: 0.39\n",
      "eval avg reward as player2 against NM: -2.20000\n",
      "eval avg ep len as player2 against NM: 16.22000\n",
      "eval_win_rate as player2 against NM: 0.43\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▋                                     | 2/30 [04:51<1:07:58, 145.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:46:48\n",
      "num of updates: 52000\n",
      "action loss: 1.18811\n",
      "eval avg reward: 8.40000\n",
      "eval avg ep len: 9.55000\n",
      "eval_win_rate: 0.92\n",
      "eval avg reward as player2: 8.40000\n",
      "eval avg ep len as player2: 8.39000\n",
      "eval_win_rate as player2: 0.92\n",
      "eval avg reward against NM: -2.60000\n",
      "eval avg ep len against NM: 12.78000\n",
      "eval_win_rate against NM: 0.37\n",
      "eval avg reward as player2 against NM: -4.10000\n",
      "eval avg ep len as player2 against NM: 15.66000\n",
      "eval_win_rate as player2 against NM: 0.33\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████                                    | 3/30 [07:17<1:05:41, 146.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:49:14\n",
      "num of updates: 53000\n",
      "action loss: 1.12247\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 7.19000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 7.30000\n",
      "eval avg ep len as player2: 9.05000\n",
      "eval_win_rate as player2: 0.87\n",
      "eval avg reward against NM: -0.80000\n",
      "eval avg ep len against NM: 11.68000\n",
      "eval_win_rate against NM: 0.46\n",
      "eval avg reward as player2 against NM: -3.90000\n",
      "eval avg ep len as player2 against NM: 16.05000\n",
      "eval_win_rate as player2 against NM: 0.35\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▎                                  | 4/30 [09:35<1:01:49, 142.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:51:32\n",
      "num of updates: 54000\n",
      "action loss: 1.07708\n",
      "eval avg reward: 8.60000\n",
      "eval avg ep len: 7.75000\n",
      "eval_win_rate: 0.93\n",
      "eval avg reward as player2: 7.80000\n",
      "eval avg ep len as player2: 8.71000\n",
      "eval_win_rate as player2: 0.89\n",
      "eval avg reward against NM: -2.00000\n",
      "eval avg ep len against NM: 12.22000\n",
      "eval_win_rate against NM: 0.40\n",
      "eval avg reward as player2 against NM: -3.40000\n",
      "eval avg ep len as player2 against NM: 16.42000\n",
      "eval_win_rate as player2 against NM: 0.39\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████                                   | 5/30 [11:50<58:21, 140.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:53:47\n",
      "num of updates: 55000\n",
      "action loss: 1.04265\n",
      "eval avg reward: 8.40000\n",
      "eval avg ep len: 8.55000\n",
      "eval_win_rate: 0.92\n",
      "eval avg reward as player2: 6.30000\n",
      "eval avg ep len as player2: 8.97000\n",
      "eval_win_rate as player2: 0.82\n",
      "eval avg reward against NM: 0.60000\n",
      "eval avg ep len against NM: 12.86000\n",
      "eval_win_rate against NM: 0.53\n",
      "eval avg reward as player2 against NM: -5.30000\n",
      "eval avg ep len as player2 against NM: 16.01000\n",
      "eval_win_rate as player2 against NM: 0.26\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▍                                 | 6/30 [14:05<55:20, 138.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:56:02\n",
      "num of updates: 56000\n",
      "action loss: 1.01261\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 8.69000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 8.10000\n",
      "eval avg ep len as player2: 8.83000\n",
      "eval_win_rate as player2: 0.91\n",
      "eval avg reward against NM: 0.80000\n",
      "eval avg ep len against NM: 12.51000\n",
      "eval_win_rate against NM: 0.54\n",
      "eval avg reward as player2 against NM: -0.30000\n",
      "eval avg ep len as player2 against NM: 15.57000\n",
      "eval_win_rate as player2 against NM: 0.50\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▊                                | 7/30 [16:24<53:00, 138.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 1:58:21\n",
      "num of updates: 57000\n",
      "action loss: 0.98481\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 7.89000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 8.80000\n",
      "eval avg ep len as player2: 7.97000\n",
      "eval_win_rate as player2: 0.94\n",
      "eval avg reward against NM: -2.40000\n",
      "eval avg ep len against NM: 12.84000\n",
      "eval_win_rate against NM: 0.38\n",
      "eval avg reward as player2 against NM: -3.00000\n",
      "eval avg ep len as player2 against NM: 14.92000\n",
      "eval_win_rate as player2 against NM: 0.37\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████▏                              | 8/30 [18:58<52:32, 143.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:00:55\n",
      "num of updates: 58000\n",
      "action loss: 0.96286\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.82000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 8.20000\n",
      "eval avg ep len as player2: 8.68000\n",
      "eval_win_rate as player2: 0.91\n",
      "eval avg reward against NM: -1.20000\n",
      "eval avg ep len against NM: 14.90000\n",
      "eval_win_rate against NM: 0.44\n",
      "eval avg reward as player2 against NM: -3.20000\n",
      "eval avg ep len as player2 against NM: 15.73000\n",
      "eval_win_rate as player2 against NM: 0.37\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▌                             | 9/30 [21:35<51:44, 147.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:03:32\n",
      "num of updates: 59000\n",
      "action loss: 0.94002\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 8.22000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 8.40000\n",
      "eval avg ep len as player2: 8.42000\n",
      "eval_win_rate as player2: 0.92\n",
      "eval avg reward against NM: 0.60000\n",
      "eval avg ep len against NM: 12.97000\n",
      "eval_win_rate against NM: 0.53\n",
      "eval avg reward as player2 against NM: -2.50000\n",
      "eval avg ep len as player2 against NM: 15.81000\n",
      "eval_win_rate as player2 against NM: 0.41\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████▋                           | 10/30 [24:43<53:23, 160.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:06:40\n",
      "num of updates: 60000\n",
      "action loss: 0.92603\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 8.36000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 8.10000\n",
      "eval avg ep len as player2: 8.09000\n",
      "eval_win_rate as player2: 0.91\n",
      "eval avg reward against NM: -1.00000\n",
      "eval avg ep len against NM: 14.37000\n",
      "eval_win_rate against NM: 0.45\n",
      "eval avg reward as player2 against NM: -3.80000\n",
      "eval avg ep len as player2 against NM: 16.19000\n",
      "eval_win_rate as player2 against NM: 0.35\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████                          | 11/30 [28:28<56:58, 179.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:10:25\n",
      "num of updates: 61000\n",
      "action loss: 0.90783\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 8.72000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 6.60000\n",
      "eval avg ep len as player2: 8.73000\n",
      "eval_win_rate as player2: 0.83\n",
      "eval avg reward against NM: 0.60000\n",
      "eval avg ep len against NM: 13.51000\n",
      "eval_win_rate against NM: 0.53\n",
      "eval avg reward as player2 against NM: -2.60000\n",
      "eval avg ep len as player2 against NM: 15.88000\n",
      "eval_win_rate as player2 against NM: 0.40\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████▍                        | 12/30 [32:24<59:04, 196.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:14:21\n",
      "num of updates: 62000\n",
      "action loss: 0.89315\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 7.61000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 7.40000\n",
      "eval avg ep len as player2: 8.95000\n",
      "eval_win_rate as player2: 0.87\n",
      "eval avg reward against NM: 4.00000\n",
      "eval avg ep len against NM: 12.90000\n",
      "eval_win_rate against NM: 0.70\n",
      "eval avg reward as player2 against NM: -0.80000\n",
      "eval avg ep len as player2 against NM: 16.33000\n",
      "eval_win_rate as player2 against NM: 0.49\n",
      "max avg reward: 9.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best_againstNM.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|█████████████████▊                       | 13/30 [35:56<57:09, 201.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:17:53\n",
      "num of updates: 63000\n",
      "action loss: 0.88017\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 8.58000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 8.00000\n",
      "eval avg ep len as player2: 8.66000\n",
      "eval_win_rate as player2: 0.90\n",
      "eval avg reward against NM: 1.60000\n",
      "eval avg ep len against NM: 11.05000\n",
      "eval_win_rate against NM: 0.58\n",
      "eval avg reward as player2 against NM: -2.20000\n",
      "eval avg ep len as player2 against NM: 15.26000\n",
      "eval_win_rate as player2 against NM: 0.40\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████▏                     | 14/30 [39:55<56:44, 212.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:21:52\n",
      "num of updates: 64000\n",
      "action loss: 0.86454\n",
      "eval avg reward: 8.40000\n",
      "eval avg ep len: 8.83000\n",
      "eval_win_rate: 0.92\n",
      "eval avg reward as player2: 9.20000\n",
      "eval avg ep len as player2: 8.40000\n",
      "eval_win_rate as player2: 0.96\n",
      "eval avg reward against NM: 0.80000\n",
      "eval avg ep len against NM: 13.99000\n",
      "eval_win_rate against NM: 0.54\n",
      "eval avg reward as player2 against NM: -2.00000\n",
      "eval avg ep len as player2 against NM: 16.07000\n",
      "eval_win_rate as player2 against NM: 0.44\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████▌                    | 15/30 [43:40<54:08, 216.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:25:37\n",
      "num of updates: 65000\n",
      "action loss: 0.85194\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 7.89000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 7.80000\n",
      "eval avg ep len as player2: 8.81000\n",
      "eval_win_rate as player2: 0.89\n",
      "eval avg reward against NM: 4.80000\n",
      "eval avg ep len against NM: 12.07000\n",
      "eval_win_rate against NM: 0.74\n",
      "eval avg reward as player2 against NM: -1.80000\n",
      "eval avg ep len as player2 against NM: 15.83000\n",
      "eval_win_rate as player2 against NM: 0.42\n",
      "max avg reward: 9.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best_againstNM.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████▊                   | 16/30 [47:30<51:29, 220.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:29:27\n",
      "num of updates: 66000\n",
      "action loss: 0.84419\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 7.57000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 7.60000\n",
      "eval avg ep len as player2: 8.69000\n",
      "eval_win_rate as player2: 0.88\n",
      "eval avg reward against NM: 0.80000\n",
      "eval avg ep len against NM: 12.79000\n",
      "eval_win_rate against NM: 0.54\n",
      "eval avg reward as player2 against NM: 1.10000\n",
      "eval avg ep len as player2 against NM: 16.06000\n",
      "eval_win_rate as player2 against NM: 0.61\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████▏                 | 17/30 [51:24<48:39, 224.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:33:21\n",
      "num of updates: 67000\n",
      "action loss: 0.83359\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 8.29000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 6.60000\n",
      "eval avg ep len as player2: 8.58000\n",
      "eval_win_rate as player2: 0.83\n",
      "eval avg reward against NM: 0.60000\n",
      "eval avg ep len against NM: 13.42000\n",
      "eval_win_rate against NM: 0.53\n",
      "eval avg reward as player2 against NM: -0.80000\n",
      "eval avg ep len as player2 against NM: 16.52000\n",
      "eval_win_rate as player2 against NM: 0.52\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████▌                | 18/30 [55:15<45:18, 226.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:37:12\n",
      "num of updates: 68000\n",
      "action loss: 0.82222\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 8.55000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 7.00000\n",
      "eval avg ep len as player2: 8.74000\n",
      "eval_win_rate as player2: 0.85\n",
      "eval avg reward against NM: -1.20000\n",
      "eval avg ep len against NM: 14.45000\n",
      "eval_win_rate against NM: 0.44\n",
      "eval avg reward as player2 against NM: 0.00000\n",
      "eval avg ep len as player2 against NM: 15.45000\n",
      "eval_win_rate as player2 against NM: 0.53\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|█████████████████████████▉               | 19/30 [59:10<42:00, 229.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:41:07\n",
      "num of updates: 69000\n",
      "action loss: 0.81388\n",
      "eval avg reward: 9.80000\n",
      "eval avg ep len: 8.24000\n",
      "eval_win_rate: 0.99\n",
      "eval avg reward as player2: 7.00000\n",
      "eval avg ep len as player2: 9.29000\n",
      "eval_win_rate as player2: 0.85\n",
      "eval avg reward against NM: 2.80000\n",
      "eval avg ep len against NM: 13.72000\n",
      "eval_win_rate against NM: 0.64\n",
      "eval avg reward as player2 against NM: -1.30000\n",
      "eval avg ep len as player2 against NM: 15.87000\n",
      "eval_win_rate as player2 against NM: 0.45\n",
      "max avg reward: 9.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████             | 20/30 [1:03:03<38:21, 230.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:45:00\n",
      "num of updates: 70000\n",
      "action loss: 0.80859\n",
      "eval avg reward: 8.20000\n",
      "eval avg ep len: 8.78000\n",
      "eval_win_rate: 0.91\n",
      "eval avg reward as player2: 7.60000\n",
      "eval avg ep len as player2: 8.21000\n",
      "eval_win_rate as player2: 0.88\n",
      "eval avg reward against NM: 5.20000\n",
      "eval avg ep len against NM: 13.04000\n",
      "eval_win_rate against NM: 0.76\n",
      "eval avg reward as player2 against NM: -2.70000\n",
      "eval avg ep len as player2 against NM: 15.85000\n",
      "eval_win_rate as player2 against NM: 0.39\n",
      "max avg reward: 9.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best_againstNM.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████▎           | 21/30 [1:06:49<34:19, 228.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:48:45\n",
      "num of updates: 71000\n",
      "action loss: 0.79778\n",
      "eval avg reward: 8.80000\n",
      "eval avg ep len: 8.37000\n",
      "eval_win_rate: 0.94\n",
      "eval avg reward as player2: 8.70000\n",
      "eval avg ep len as player2: 8.70000\n",
      "eval_win_rate as player2: 0.94\n",
      "eval avg reward against NM: 2.40000\n",
      "eval avg ep len against NM: 11.82000\n",
      "eval_win_rate against NM: 0.62\n",
      "eval avg reward as player2 against NM: -1.80000\n",
      "eval avg ep len as player2 against NM: 16.33000\n",
      "eval_win_rate as player2 against NM: 0.42\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████▌          | 22/30 [1:10:42<30:42, 230.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:52:39\n",
      "num of updates: 72000\n",
      "action loss: 0.79058\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 7.65000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 7.80000\n",
      "eval avg ep len as player2: 7.63000\n",
      "eval_win_rate as player2: 0.89\n",
      "eval avg reward against NM: 2.20000\n",
      "eval avg ep len against NM: 14.39000\n",
      "eval_win_rate against NM: 0.61\n",
      "eval avg reward as player2 against NM: -1.80000\n",
      "eval avg ep len as player2 against NM: 15.61000\n",
      "eval_win_rate as player2 against NM: 0.44\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████▉         | 23/30 [1:13:26<24:32, 210.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:55:23\n",
      "num of updates: 73000\n",
      "action loss: 0.78732\n",
      "eval avg reward: 9.00000\n",
      "eval avg ep len: 7.44000\n",
      "eval_win_rate: 0.95\n",
      "eval avg reward as player2: 7.00000\n",
      "eval avg ep len as player2: 8.33000\n",
      "eval_win_rate as player2: 0.85\n",
      "eval avg reward against NM: 3.00000\n",
      "eval avg ep len against NM: 12.35000\n",
      "eval_win_rate against NM: 0.65\n",
      "eval avg reward as player2 against NM: 0.10000\n",
      "eval avg ep len as player2 against NM: 15.19000\n",
      "eval_win_rate as player2 against NM: 0.53\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████▏       | 24/30 [1:17:25<21:53, 218.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 2:59:22\n",
      "num of updates: 74000\n",
      "action loss: 0.77647\n",
      "eval avg reward: 8.60000\n",
      "eval avg ep len: 7.74000\n",
      "eval_win_rate: 0.93\n",
      "eval avg reward as player2: 8.00000\n",
      "eval avg ep len as player2: 8.17000\n",
      "eval_win_rate as player2: 0.90\n",
      "eval avg reward against NM: 1.20000\n",
      "eval avg ep len against NM: 13.60000\n",
      "eval_win_rate against NM: 0.56\n",
      "eval avg reward as player2 against NM: 1.40000\n",
      "eval avg ep len as player2 against NM: 17.23000\n",
      "eval_win_rate as player2 against NM: 0.66\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████▌      | 25/30 [1:21:18<18:35, 223.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 3:03:15\n",
      "num of updates: 75000\n",
      "action loss: 0.76983\n",
      "eval avg reward: 9.20000\n",
      "eval avg ep len: 8.77000\n",
      "eval_win_rate: 0.96\n",
      "eval avg reward as player2: 7.40000\n",
      "eval avg ep len as player2: 8.74000\n",
      "eval_win_rate as player2: 0.87\n",
      "eval avg reward against NM: 3.60000\n",
      "eval avg ep len against NM: 13.99000\n",
      "eval_win_rate against NM: 0.68\n",
      "eval avg reward as player2 against NM: -1.50000\n",
      "eval avg ep len as player2 against NM: 15.63000\n",
      "eval_win_rate as player2 against NM: 0.44\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████▊     | 26/30 [1:25:12<15:05, 226.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 3:07:09\n",
      "num of updates: 76000\n",
      "action loss: 0.76597\n",
      "eval avg reward: 8.60000\n",
      "eval avg ep len: 8.19000\n",
      "eval_win_rate: 0.93\n",
      "eval avg reward as player2: 7.80000\n",
      "eval avg ep len as player2: 8.66000\n",
      "eval_win_rate as player2: 0.89\n",
      "eval avg reward against NM: 2.00000\n",
      "eval avg ep len against NM: 15.14000\n",
      "eval_win_rate against NM: 0.60\n",
      "eval avg reward as player2 against NM: -1.20000\n",
      "eval avg ep len as player2 against NM: 15.87000\n",
      "eval_win_rate as player2 against NM: 0.48\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████    | 27/30 [1:28:50<11:11, 223.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 3:10:47\n",
      "num of updates: 77000\n",
      "action loss: 0.75737\n",
      "eval avg reward: 8.20000\n",
      "eval avg ep len: 8.39000\n",
      "eval_win_rate: 0.91\n",
      "eval avg reward as player2: 7.80000\n",
      "eval avg ep len as player2: 8.46000\n",
      "eval_win_rate as player2: 0.89\n",
      "eval avg reward against NM: 2.00000\n",
      "eval avg ep len against NM: 13.32000\n",
      "eval_win_rate against NM: 0.60\n",
      "eval avg reward as player2 against NM: 1.20000\n",
      "eval avg ep len as player2 against NM: 16.20000\n",
      "eval_win_rate as player2 against NM: 0.58\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████▍  | 28/30 [1:32:50<07:37, 228.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 3:14:47\n",
      "num of updates: 78000\n",
      "action loss: 0.75151\n",
      "eval avg reward: 8.40000\n",
      "eval avg ep len: 8.81000\n",
      "eval_win_rate: 0.92\n",
      "eval avg reward as player2: 8.20000\n",
      "eval avg ep len as player2: 8.52000\n",
      "eval_win_rate as player2: 0.91\n",
      "eval avg reward against NM: 0.00000\n",
      "eval avg ep len against NM: 13.64000\n",
      "eval_win_rate against NM: 0.50\n",
      "eval avg reward as player2 against NM: 0.60000\n",
      "eval avg ep len as player2 against NM: 16.77000\n",
      "eval_win_rate as player2 against NM: 0.57\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████▋ | 29/30 [1:36:33<03:47, 227.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 3:18:30\n",
      "num of updates: 79000\n",
      "action loss: 0.74519\n",
      "eval avg reward: 9.40000\n",
      "eval avg ep len: 8.46000\n",
      "eval_win_rate: 0.97\n",
      "eval avg reward as player2: 8.80000\n",
      "eval avg ep len as player2: 7.95000\n",
      "eval_win_rate as player2: 0.94\n",
      "eval avg reward against NM: 2.60000\n",
      "eval avg ep len against NM: 13.18000\n",
      "eval_win_rate against NM: 0.63\n",
      "eval avg reward as player2 against NM: 0.00000\n",
      "eval avg ep len as player2 against NM: 16.42000\n",
      "eval_win_rate as player2 against NM: 0.53\n",
      "max avg reward: 9.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 30/30 [1:40:23<00:00, 200.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 3:22:20\n",
      "num of updates: 80000\n",
      "action loss: 0.74033\n",
      "eval avg reward: 8.60000\n",
      "eval avg ep len: 8.75000\n",
      "eval_win_rate: 0.93\n",
      "eval avg reward as player2: 7.80000\n",
      "eval avg ep len as player2: 8.47000\n",
      "eval_win_rate as player2: 0.89\n",
      "eval avg reward against NM: 5.20000\n",
      "eval avg ep len against NM: 11.82000\n",
      "eval_win_rate against NM: 0.76\n",
      "eval avg reward as player2 against NM: -1.30000\n",
      "eval avg ep len as player2 against NM: 16.24000\n",
      "eval_win_rate as player2 against NM: 0.47\n",
      "max avg reward: 9.80000\n",
      "saving max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best_againstNM.pt\n",
      "saving current model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_80000.pt\n",
      "============================================================\n",
      "finished training!\n",
      "============================================================\n",
      "started training at: 23-02-28-17-54-34\n",
      "finished training at: 23-02-28-21-16-54\n",
      "total training time: 3:22:20\n",
      "max avg reward: 9.80000\n",
      "saved max avg reward model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34_best.pt\n",
      "saved last updated model at: ./dt_training/dt_Connect4_batch_size=64_context_len=10_n_blocks=4_hidden_dim=128_n_heads=2_model_23-02-28-17-54-34.pt\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [read_list('Dataset/RandomAgentVsRandomAgentDatasetWithoutDups'),\n",
    "            read_list('Dataset/NegaMaxAgentVsRandomAgentDatasetWithoutDups'), \n",
    "            read_list('Dataset/NegaMaxAgentVsNegaMaxAgentDatasetWithoutDups')]\n",
    "\n",
    "max_train_iters = [20, 30, 30]\n",
    "\n",
    "# start training\n",
    "for i in range(len(datasets)):\n",
    "    # update dataset\n",
    "    traj_dataset = TrajectoryDataset(datasets[i], context_len)\n",
    "    \n",
    "    # Create DataLoader for dataset\n",
    "    traj_data_loader = DataLoader(traj_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=True) \n",
    "\n",
    "    data_iter = iter(traj_data_loader)\n",
    "\n",
    "    for i_train_iter in tqdm(range(max_train_iters[i])):\n",
    "\n",
    "        log_action_losses = []\n",
    "        agent.model.train()\n",
    "\n",
    "        for _ in range(num_updates_per_iter):\n",
    "            try:\n",
    "                timesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
    "            except StopIteration:\n",
    "                data_iter = iter(traj_data_loader)\n",
    "                timesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
    "\n",
    "            timesteps = timesteps.to(device)    # batch_size x traj_length\n",
    "            states = states.to(device)          # batch_size x traj_length x state_dim\n",
    "            actions = actions.to(device)        # batch_size x traj_length x act_dim\n",
    "            returns_to_go = returns_to_go.to(device).unsqueeze(dim=-1) # batch_size x traj_length x 1\n",
    "            traj_mask = traj_mask.to(device)    # B x T\n",
    "\n",
    "            _, loss = agent.model.forward(timesteps=timesteps, \n",
    "                                                            states=states, \n",
    "                                                            actions=actions, \n",
    "                                                            returns_to_go=returns_to_go,\n",
    "                                                            traj_mask = traj_mask)\n",
    "            \n",
    "            # optimize loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.requires_grad_()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(agent.model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            log_action_losses.append(loss.detach().cpu().item())\n",
    "\n",
    "        # evaluate on env\n",
    "        results = evaluate_on_env(agent, randomPlayer, \"p1\", env, num_eval_ep, max_timestep)\n",
    "\n",
    "        resultsPlayer2 = evaluate_on_env(agent, randomPlayer, \"p2\", env, num_eval_ep, max_timestep)\n",
    "\n",
    "        resultsAgainstNM = evaluate_on_env(agent, negaMax, \"p1\", env, num_eval_ep, max_timestep)\n",
    "\n",
    "        resultsPlayer2AgainstNM = evaluate_on_env(agent, negaMax, \"p2\", env, num_eval_ep, max_timestep)\n",
    "\n",
    "        # get the results from the evaluation\n",
    "        eval_avg_reward = results['avg_reward']\n",
    "        eval_avg_ep_len = results['avg_ep_len']\n",
    "        eval_win_rate = results['win_rate']\n",
    "\n",
    "        eval_avg_reward_player2 = resultsPlayer2['avg_reward']\n",
    "        eval_avg_ep_len_player2 = resultsPlayer2['avg_ep_len']\n",
    "        eval_win_rate_player2 = resultsPlayer2['win_rate']\n",
    "\n",
    "        eval_avg_reward_AgainstNM = resultsAgainstNM['avg_reward']\n",
    "        eval_avg_ep_len_AgainstNM = resultsAgainstNM['avg_ep_len']\n",
    "        eval_win_rate_AgainstNM = resultsAgainstNM['win_rate']\n",
    "\n",
    "        eval_avg_reward_player2_AgainstNM = resultsPlayer2AgainstNM['avg_reward']\n",
    "        eval_avg_ep_len_player2_AgainstNM = resultsPlayer2AgainstNM['avg_ep_len']\n",
    "        eval_win_rate_player2_AgainstNM = resultsPlayer2AgainstNM['win_rate']\n",
    "\n",
    "\n",
    "        mean_action_loss = np.mean(log_action_losses)\n",
    "        time_elapsed = str(datetime.now().replace(microsecond=0) - start_time)\n",
    "\n",
    "        total_updates += num_updates_per_iter\n",
    "        \n",
    "        # print results\n",
    "        log_str = (\"=\" * 60 + '\\n' +\n",
    "                \"time elapsed: \" + time_elapsed  + '\\n' +\n",
    "                \"num of updates: \" + str(total_updates) + '\\n' +\n",
    "                \"action loss: \" +  format(mean_action_loss, \".5f\") + '\\n' +\n",
    "                \"eval avg reward: \" + format(eval_avg_reward, \".5f\") + '\\n' +\n",
    "                \"eval avg ep len: \" + format(eval_avg_ep_len, \".5f\") + '\\n' +\n",
    "                \"eval_win_rate: \" + format(eval_win_rate, \".2f\") + '\\n'\n",
    "                \"eval avg reward as player2: \" + format(eval_avg_reward_player2, \".5f\") + '\\n' +\n",
    "                \"eval avg ep len as player2: \" + format(eval_avg_ep_len_player2, \".5f\") + '\\n' +\n",
    "                \"eval_win_rate as player2: \" + format(eval_win_rate_player2, \".2f\") + '\\n' +\n",
    "                \"eval avg reward against NM: \" + format(eval_avg_reward_AgainstNM, \".5f\") + '\\n' +\n",
    "                \"eval avg ep len against NM: \" + format(eval_avg_ep_len_AgainstNM, \".5f\") + '\\n' +\n",
    "                \"eval_win_rate against NM: \" + format(eval_win_rate_AgainstNM, \".2f\") + '\\n' + \n",
    "                \"eval avg reward as player2 against NM: \" + format(eval_avg_reward_player2_AgainstNM, \".5f\") + '\\n' +\n",
    "                \"eval avg ep len as player2 against NM: \" + format(eval_avg_ep_len_player2_AgainstNM, \".5f\") + '\\n' +\n",
    "                \"eval_win_rate as player2 against NM: \" + format(eval_win_rate_player2_AgainstNM, \".2f\"))\n",
    "\n",
    "        print(log_str)\n",
    "        \n",
    "        # save results in csv\n",
    "        log_data = [time_elapsed, total_updates, mean_action_loss,\n",
    "                    eval_avg_reward, eval_avg_ep_len, \n",
    "                    eval_win_rate, eval_avg_reward_player2,\n",
    "                    eval_avg_ep_len_player2, \n",
    "                    eval_win_rate_player2,\n",
    "                    eval_avg_reward_AgainstNM, eval_avg_ep_len_AgainstNM,\n",
    "                    eval_win_rate_AgainstNM,\n",
    "                    eval_avg_reward_player2_AgainstNM, eval_avg_ep_len_player2_AgainstNM,\n",
    "                    eval_win_rate_player2_AgainstNM]\n",
    "\n",
    "        csv_writer.writerow(log_data)\n",
    "\n",
    "        # save best model against random\n",
    "        print(\"max avg reward: \" + format(max_avg_reward, \".5f\"))\n",
    "        if eval_avg_reward >= max_avg_reward:\n",
    "            print(\"saving max avg reward model at: \" + save_best_model_path)\n",
    "            torch.save(agent.model.state_dict(), save_best_model_path)\n",
    "            max_avg_reward = eval_avg_reward\n",
    "        # save best model against negaMax\n",
    "        if eval_avg_reward_AgainstNM >= max_avg_reward_NM:\n",
    "            print(\"saving max avg reward model at: \" + save_best_model_path_NM)\n",
    "            torch.save(agent.model.state_dict(), save_best_model_path_NM)\n",
    "            max_avg_reward_NM = eval_avg_reward_AgainstNM\n",
    "\n",
    "    \n",
    "    currentModelPath = save_model_path[:-3] + \"_\" + str(total_updates) + \".pt\"\n",
    "    print(\"saving current model at: \" + currentModelPath)\n",
    "    torch.save(agent.model.state_dict(), currentModelPath)\n",
    "\n",
    "\n",
    "final_model_path = save_model_path      \n",
    "torch.save(agent.model.state_dict(), final_model_path)\n",
    "                                             \n",
    "print(\"=\" * 60)\n",
    "print(\"finished training!\")\n",
    "print(\"=\" * 60)\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "time_elapsed = str(end_time - start_time)\n",
    "end_time_str = end_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "print(\"started training at: \" + start_time_str)\n",
    "print(\"finished training at: \" + end_time_str)\n",
    "print(\"total training time: \" + time_elapsed)\n",
    "print(\"max avg reward: \" + format(max_avg_reward, \".5f\"))\n",
    "print(\"saved max avg reward model at: \" + save_best_model_path)\n",
    "print(\"saved last updated model at: \" + save_model_path)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "csv_writer = open(log_path, 'a', 1).close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDNN",
   "language": "python",
   "name": "pdnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
