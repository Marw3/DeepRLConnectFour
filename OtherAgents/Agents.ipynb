{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53091c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent():\n",
    "    def __init__(self):\n",
    "        self.policy_net = None\n",
    "        self.target_net = None\n",
    "        self.memory = None\n",
    "        \n",
    "    def select_action(self, state, available_actions, EPS = 0, training=True):\n",
    "        return random.choice(available_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def select_action(self, state = None, available_actions = None, EPS = 0, training=True):\n",
    "        action = -1\n",
    "        while(action not in available_actions):\n",
    "            action = int(input(\"Choose a number in {}\".format(available_actions)))\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df67d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.kaggle.com/code/etchourdakis/connect-4-negamax-agent-with-memoization\n",
    "\n",
    "class NegaMaxAgent():\n",
    "    def __init__(self, env, depth):\n",
    "        self.env = env\n",
    "        self.policy_net = None\n",
    "        self.target_net = None\n",
    "        self.memory = None\n",
    "        self.depth = depth\n",
    "\n",
    "    def negamax(\n",
    "    self,\n",
    "    state, \n",
    "    depth, \n",
    "    alpha, \n",
    "    beta, \n",
    "    color, \n",
    "    ttlut\n",
    "    ):\n",
    "        \"\"\"\n",
    "            A negamax function with alpha-beta pruning and memoization.\n",
    "\n",
    "            :param tuple state: A tuple where state[0] is the game board\n",
    "                                at that state and state[1] the last column\n",
    "                                played.\n",
    "            :param int depth:   The depth examined. While visually we say\n",
    "                                the tree is traversed form lower to higher\n",
    "                                depth, here it is the opposite, so the leaves\n",
    "                                will be at depth 0.\n",
    "            :param float alpha: Parameter alpha for alpha beta pruning.\n",
    "            :param float beta:  Parameter beta for alpha beta pruning.\n",
    "            :param int color:   The player color (e.g. red or blue). Here its \n",
    "                                always 1 for the player, and -1 for the opponent.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store original alpha value, will be used later.\n",
    "        alphaOrig = alpha\n",
    "\n",
    "        # Tranform the board to a hashable tuple to be able to be\n",
    "        # looked up in ttlut.\n",
    "        node = tuple(state[0].flatten().tolist())\n",
    "\n",
    "        # If we have already a record about node at a higher depth\n",
    "        # retrieve its value. The node might be storing the exact\n",
    "        # value, or an upper or lower bound.\n",
    "        if ttlut[node]['valid'] and ttlut[node]['depth'] >= depth:\n",
    "            if ttlut[node]['flag'] == 'EXACT':\n",
    "                return ttlut[node]['value']\n",
    "            elif ttlut[node]['flag'] == 'LOWERBOUND':\n",
    "                alpha = max(alpha, ttlut[node]['value'])\n",
    "            elif ttlut[node]['flag'] == 'UPPERBOUND':\n",
    "                beta = min(alpha, ttlut[node]['value'])\n",
    "\n",
    "            if alpha >= beta:\n",
    "                return ttlut[node]['value']\n",
    "\n",
    "        # Check whether the node is terminal and if so return a heuristic\n",
    "        # value of it.\n",
    "        if  self.is_terminal(state, ttlut):\n",
    "            val =  color * self.eval_function(state, ttlut)\n",
    "            return val\n",
    "\n",
    "        # Check if we are at the maximum (here minimum) depth we can look ahead\n",
    "        # and if so, return a heuristic value of it.\n",
    "        if depth <= 0:\n",
    "            return color * self.eval_function(state, ttlut)\n",
    "\n",
    "        # Set initial value as -infinity\n",
    "        value = -np.inf\n",
    "\n",
    "        # Get the children of the current state. We do not really need to pass color here\n",
    "        # however it speeds up computation (we do not need to count pieces in the board)\n",
    "        # to see whether the number of pieces is odd or even.\n",
    "        children = self.get_children(state)\n",
    "\n",
    "        # Some values are going to be equal, add some randomization so that when sorting \n",
    "        # those will not always be sorted the same way.\n",
    "        random.shuffle(children)    \n",
    "\n",
    "        # Sort the children according to increasing value\n",
    "        children = sorted(children, key=lambda x: self.eval_function(x, ttlut))\n",
    "        for child in children:\n",
    "\n",
    "            # The rational opponent's play would maximize their negamax value so we should\n",
    "            # always assume they pick the move which maximizes it so we should choose the \n",
    "            # same value when calculating our overall value. Since the opponent's value is going\n",
    "            # to be of opposite sign, multiply it with -1.\n",
    "            value = max(value, -self.negamax(child, depth-1, -beta, -alpha, -color, ttlut))\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "            # If it's over an upper bound, break the loop and do not examine any more states.\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "\n",
    "\n",
    "        # Since we already did the labour of getting the values for this state, save them\n",
    "        # to a look-up table for future use.\n",
    "        ttlut[node]['value'] = value\n",
    "        if value <= alphaOrig:\n",
    "            ttlut[node]['flag'] = 'UPPERBOUND'\n",
    "        elif value >= beta:\n",
    "            ttlut[node]['flag'] = 'LOWERBOUND'\n",
    "        else:\n",
    "            ttlut[node]['flag'] = 'EXACT'\n",
    "\n",
    "        ttlut[node]['depth'] = depth\n",
    "        ttlut[node]['valid'] = True\n",
    "\n",
    "        return value\n",
    "\n",
    "    def h(self, state, X=4):\n",
    "        \"\"\"\n",
    "            A heuristic function for Connect-X.\n",
    "\n",
    "            :param tuple state: the (board, action) tuple state.\n",
    "            :param int X: The number of chess pieces we expect a group of to\n",
    "                          win. In Connect-4 this is X=4.\n",
    "        \"\"\"\n",
    "\n",
    "        board, piece_j, piece_i = state\n",
    "\n",
    "        # For a full group (therefore a win or loss), assign infinite value.\n",
    "        GROUPX = np.inf \n",
    "\n",
    "        # Start with a value of 0\n",
    "        hval = 0\n",
    "\n",
    "        # Select heuristic value based on Player A's POV. In case the last action\n",
    "        # was the player's opponent (color=-1) we need to invert the result since\n",
    "        # the state is now damaging for the player.\n",
    "        color = board[piece_i][piece_j]\n",
    "\n",
    "        # Add to the value according to which column the piece was put into. Emphasize middle\n",
    "        # columns more.\n",
    "        if piece_j == 3:\n",
    "            hval = 200\n",
    "        elif piece_j in [2,4]:\n",
    "            hval = 120\n",
    "        elif piece_j in [1,5]:\n",
    "            hval = 70\n",
    "        else:\n",
    "            hval = 40\n",
    "\n",
    "        # Get the number of rows and columns of the board.\n",
    "        nCols = board.shape[1]\n",
    "        nRows = board.shape[0]\n",
    "\n",
    "        # Below we count whether the action led to full groups, full-1 groups, etc.\n",
    "        # We count whether the groups were formed in horizontal lines, vertical lines,\n",
    "        # diagonally, or counter diagonally.\n",
    "\n",
    "        # For horizontal lines. Count initial piece.\n",
    "        count = 1\n",
    "\n",
    "        # This checks whether the two edges are open\n",
    "        openPoints = 0\n",
    "\n",
    "        # Count right\n",
    "        if piece_j < nCols - 1:\n",
    "            for j in range(piece_j+1, min(piece_j+X, nCols)):\n",
    "\n",
    "                # If already formed a full group, no need to\n",
    "                # calculate further.\n",
    "                if count == X:\n",
    "                    return color*GROUPX\n",
    "\n",
    "                # If the pieces are all the same\n",
    "                # color, keep counting, else break.\n",
    "                if board[piece_i][j] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[piece_i][j] == 0:\n",
    "                        openPoints += 1\n",
    "                    break\n",
    "\n",
    "        # Do we have a full group already?\n",
    "        if count == X:\n",
    "            return color*GROUPX      \n",
    "\n",
    "        # Count left\n",
    "        if piece_j > 0:\n",
    "            for j in range(piece_j-1, max(0, piece_j-X) -1, -1):\n",
    "                if count == X:\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    return color*GROUPX\n",
    "\n",
    "                if board[piece_i][j] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[piece_i][j] == 0:\n",
    "                        openPoints += 1                \n",
    "                    break\n",
    "\n",
    "        if count == X:\n",
    "            return color*GROUPX     \n",
    "\n",
    "        # IF we do not have a full group but we have a X-1 group, add\n",
    "        # to the value.\n",
    "        if count == X-1:\n",
    "            if openPoints == 2:\n",
    "                hval += 900000\n",
    "            elif openPoints == 1:\n",
    "                hval += 50000\n",
    "\n",
    "        if count == X-2:\n",
    "            if openPoints == 2:\n",
    "                hval += 4000\n",
    "            elif openPoints == 1:\n",
    "                hval += 3000\n",
    "\n",
    "        # Count vertically same as above but on the vertical dimension.\n",
    "        # Note that here we do not need to count upwards since there is no\n",
    "        # way to place a piece \"below\" the rest.\n",
    "        count = 1\n",
    "        openPoints = 0\n",
    "\n",
    "        if piece_i < nRows - 1:\n",
    "            for i in range(piece_i+1, min(piece_i+X, nRows)):\n",
    "                if count == X:\n",
    "                    return color*GROUPX\n",
    "\n",
    "                if board[i][piece_j] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[i][piece_j] == 0:\n",
    "                        openPoints += 1\n",
    "                    break\n",
    "\n",
    "        if count == X:\n",
    "            return color*GROUPX        \n",
    "\n",
    "        if count == X-1:\n",
    "            # This case is always open.\n",
    "            hval +=50000\n",
    "\n",
    "        if count == X-2:\n",
    "            hval +=3000    \n",
    "\n",
    "        # Count on the bottom-left to up-right diagonals\n",
    "\n",
    "        count = 1        \n",
    "        openPoints = 0\n",
    "\n",
    "        # Count up-right diagonal\n",
    "        if piece_i > 0 and piece_j < nCols - 1:\n",
    "            for d in range(1, X):\n",
    "                if count == X:\n",
    "                    return color*GROUPX\n",
    "\n",
    "                # Check if we hit the edges, break if so.\n",
    "                if piece_i - d < 0:\n",
    "                    break\n",
    "                if piece_j + d > nCols - 1:\n",
    "                    break\n",
    "\n",
    "                if board[piece_i-d, piece_j+d] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[piece_i-d, piece_j+d] == 0:\n",
    "                        openPoints += 1\n",
    "                    break\n",
    "\n",
    "        if count == X:\n",
    "            return color*GROUPX                \n",
    "\n",
    "        # Count bottom-left diagonal\n",
    "        if piece_i < nRows - 1 and piece_j > 0:\n",
    "            for d in range(1,X):\n",
    "                if count == X:\n",
    "                    return color*GROUPX\n",
    "\n",
    "                if piece_i + d > nRows - 1:\n",
    "                    break\n",
    "                if piece_j - d <0:\n",
    "                    break\n",
    "\n",
    "                if board[piece_i+d, piece_j-d] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[piece_i+d, piece_j-d] == 0:\n",
    "                        openPoints += 1\n",
    "                    break   \n",
    "\n",
    "        if count == X:\n",
    "            return color*GROUPX   \n",
    "\n",
    "        if count == X-1:\n",
    "            if openPoints == 2:\n",
    "                hval +=800000\n",
    "            elif openPoints == 1:\n",
    "                hval +=40000\n",
    "\n",
    "        if count == X-2:\n",
    "            if openPoints == 2:\n",
    "                hval +=4000\n",
    "            elif openPoints == 1:\n",
    "                hval +=3000            \n",
    "\n",
    "        # Count on the up-left, bottom-right diagonal\n",
    "        count = 1   \n",
    "        openPoints = 0\n",
    "\n",
    "        # Count up-left diagonal\n",
    "        if piece_i > 0  and piece_j > 0:\n",
    "            for d in range(1,X):\n",
    "                if count == X:\n",
    "                    return color*GROUPX\n",
    "\n",
    "                if piece_i - d < 0:\n",
    "                    break\n",
    "                if piece_j - d < 0:\n",
    "                    break\n",
    "\n",
    "                if board[piece_i-d, piece_j-d] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[piece_i-d, piece_j-d] == 0:\n",
    "                        openPoints += 1\n",
    "                    break\n",
    "\n",
    "        if count == X:\n",
    "            return color*GROUPX                \n",
    "\n",
    "        # Count bottom-right diagonal\n",
    "        if piece_i < nRows - 1 and piece_j < nCols - 1:\n",
    "            for d in range(1,X):\n",
    "                if count == X:\n",
    "                    return color*GROUPX\n",
    "\n",
    "                if piece_i + d > nRows - 1:\n",
    "                    break\n",
    "                if piece_j + d > nCols - 1:\n",
    "                    break\n",
    "\n",
    "                if board[piece_i+d, piece_j+d] == color:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if board[piece_i+d, piece_j+d] == 0:\n",
    "                        openPoints += 1\n",
    "                    break    \n",
    "\n",
    "        if count == X:\n",
    "            return color*GROUPX    \n",
    "\n",
    "        if count == X-1:\n",
    "            if openPoints == 2:\n",
    "                hval +=800000\n",
    "            elif openPoints == 1:\n",
    "                hval +=40000\n",
    "\n",
    "\n",
    "        if count == X-2:\n",
    "            if openPoints == 2:\n",
    "                hval +=4000\n",
    "            elif openPoints == 1:\n",
    "                hval +=3000      \n",
    "\n",
    "        # Return the calculated hval multiplied with the color\n",
    "        # to transform it for player A's point of view.\n",
    "        return  color*hval\n",
    "\n",
    "    def is_terminal(self, state, ttlut, X=4):\n",
    "    \n",
    "        # Again, convert to hashable.\n",
    "        node = tuple(state[0].flatten().tolist())\n",
    "\n",
    "        # If we already know it is a terminal state, skip the\n",
    "        # calculations.\n",
    "        if ttlut[node]['terminal'] == True:\n",
    "            return True\n",
    "\n",
    "        board, _, _ = state\n",
    "\n",
    "        # Check whether the number of nonzeros (occupied places)\n",
    "        # in the top row is less than the size of that row. Since \n",
    "        # the colors are either -1 or 1 the following should suffice:\n",
    "        if np.abs(board[0,:]).sum() ==  board.shape[1]:\n",
    "            ttlut[node]['terminal'] = True\n",
    "            return True\n",
    "\n",
    "        # Return if the value returned by the evaluation function is \n",
    "        # + or - infinity.\n",
    "        return np.isinf(np.abs(self.eval_function(state, ttlut, X=X)))\n",
    "    \n",
    "    def eval_function(self, state, ttlut, X=4):\n",
    "        \"\"\"\n",
    "        The evaluation function for state `state`\n",
    "\n",
    "        :param tuple state: A state tuple where state[0] is the\n",
    "                            game board at that state as a numpy array\n",
    "                            and state[1] is the last action at that \n",
    "                            state.\n",
    "        :param defaultdict ttlut: \n",
    "                            A look up table.\n",
    "        \"\"\"\n",
    "\n",
    "        # Again, convert the state to a hashable form.\n",
    "        node = tuple(state[0].flatten().tolist())\n",
    "\n",
    "        # If the heuristic value returned by h does not exist,\n",
    "        # add it to the table, else return it.\n",
    "        if ttlut[node]['h'] is not None:\n",
    "            val =  ttlut[node]['h']\n",
    "            return val\n",
    "        else:\n",
    "            val = self.h(state, X=4)\n",
    "            ttlut[node]['h'] = val\n",
    "            return val\n",
    "\n",
    "    def nega_max_decision(self, state, depth, ttlut):\n",
    "        # Get possible actions as children states\n",
    "        children = self.get_children(state,  first_move=True)    \n",
    "\n",
    "\n",
    "        # Shuffle them so that when picking the maximum value we do not just pick the same action over and over\n",
    "        # when some actions are equivalent (e.g. the symmetic of a column with the column are expected to have\n",
    "        # the same value)\n",
    "        random.shuffle(children)\n",
    "\n",
    "        # Pick an initial decision just in case we cannot find a better one.\n",
    "        child_board, decision, decision_row = children[0]    \n",
    "\n",
    "        # This step is similar to what's in negamax with the addition we return the best decision.\n",
    "        value = -np.inf\n",
    "        for child in children:\n",
    "            new_value = -self.negamax(child, depth-1, -np.inf, np.inf, -1, ttlut)\n",
    "            if new_value > value:\n",
    "                decision = child[1]\n",
    "                value = new_value         \n",
    "\n",
    "        return decision\n",
    "\n",
    "    def select_action(self, state, available_actions, EPS = 0, training=False):    \n",
    "        # Convert the colours from the observed colour marks (usually 1 and 2) to 1 for player and -1 for opponent.\n",
    "        color = state[self.env.last_action_row][self.env.last_action]\n",
    "        \n",
    "        if color == 1:\n",
    "            board = -1*state.copy()\n",
    "        else:\n",
    "            board = state.copy()\n",
    "        # Initialize the look up table.\n",
    "        ttlut = defaultdict(lambda:{'terminal':False, 'depth':-1000, 'flag': '', 'value': -10000, 'valid':False, 'h':None})\n",
    "\n",
    "        # Set up the root node. \n",
    "        state = (board, self.env.last_action, self.env.last_action_row)\n",
    "\n",
    "        # Initially there is no need to have the depth too high, \n",
    "        # increase it slowly.\n",
    "\n",
    "        # Figure out what step we are in.\n",
    "        step = np.abs(board).sum() + 1\n",
    "\n",
    "        # Set the maximum depth. It has to be chosen as such it does not return a timeout. \n",
    "        max_depth = self.depth\n",
    "\n",
    "        decision = self.nega_max_decision(state, max_depth, ttlut)\n",
    "        # Finally, return the decision that maximizes the -negamax value shown above, or the default from the first child.\n",
    "        return decision\n",
    "    \n",
    "    def add_piece_column(self, board, color, c):\n",
    "        \"\"\" \n",
    "            Adds piece of color `color` on column `c`. Returns the row of that piece.\n",
    "\n",
    "            :param np.ndarray board: the game board at that state\n",
    "            :param int color: 1 or -1, the piece color\n",
    "        \"\"\"\n",
    "        if c >= 0:    \n",
    "            column = board[:, c]\n",
    "            for cc in range(len(column)-1,-1,-1):\n",
    "                if column[cc] == 0:\n",
    "                    column[cc] = color\n",
    "                    return cc\n",
    "\n",
    "        return -1\n",
    "\n",
    "    def get_children(self, state, first_move=False):\n",
    "        \"\"\"\n",
    "            Returns a list of children-states.\n",
    "\n",
    "            :param tuple state: the state tuple\n",
    "            :param int color: the current player, 1 or -1.\n",
    "        \"\"\"\n",
    "\n",
    "        board, j, i = state\n",
    "        color = board[i][j]\n",
    "\n",
    "        # If the board is empty, the agent plays the first move, therefore:\n",
    "        if first_move:\n",
    "            color = 1\n",
    "        else:\n",
    "            color = -color\n",
    "        children = []\n",
    "\n",
    "        for c in range(board.shape[1]):\n",
    "            # We can insert a new chesspiece in a non-full column. Since the bottom positions\n",
    "            # of a column get filled first, we can check whether a column is empty by just checking the top\n",
    "            # row (0).\n",
    "            if board[0,c] == 0:\n",
    "\n",
    "                # Copy the current board. \n",
    "                child_board = board.copy()\n",
    "                #import pdb; pdb.set_trace()\n",
    "\n",
    "                # Add a mark in column c.\n",
    "                row = self.add_piece_column(child_board, color, c)\n",
    "\n",
    "                # Create a new state for the child and add\n",
    "                # it to the list of children.\n",
    "                child_state = (child_board, c, row)\n",
    "                children.append(child_state)\n",
    "\n",
    "\n",
    "        return children    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fe7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
